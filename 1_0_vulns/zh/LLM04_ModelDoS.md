LLM04: 模型拒绝服务
 攻击者与 LLM 进行交互的方式会消耗大量资源，从而导致他们和其他用户的服务质量下降，并可能产生高昂的资源成本。此外，一个新出现的主要安全问题是攻击者可能干扰或操纵大语言模型的上下文窗口。由于 LLM 在各种应用程序中的使用越来越多、资源利用率很高、用户输入的不可预测性以及开发人员普遍不了解此威胁，因此该问题变得越来越严重。在大语言模型中，上下文窗口表示模型可以管理的文本的最大长度，涵盖输入和输出。这是大语言模型的一个重要特征，因为它决定了模型可以理解的语言模式的复杂性以及它在任何给定时间可以处理的文本的大小。上下文窗口的大小由模型的体系结构定义，并且在模型之间可能有所不同。
 威胁的常见示例
 
1. 通过在队列中大量生成任务（例如使用 LangChain 或 AutoGPT）提出导致重复使用资源的查询。
2. 发送异常消耗资源的查询，可能是因为它们使用不寻常的拼写或序列。
3. 连续输入溢出: 攻击者向LLM发送超出其上下文窗口的输入流，导致模型消耗过多的计算资源。
4. 重复的长输入: 攻击者重复向 LLM 发送长输入，每个输入都超过上下文窗口。
5. 递归上下文扩展: 攻击者构建触发递归上下文扩展的输入，迫使LLM重复扩展和处理上下文窗口。
6. 可变长度输入（Flooding）洪水攻击: 攻击者用大量可变长度输入淹没 LLM的上下文窗口，其中每个输入都经过精心设计，以达到上下文窗口的限制。该技术旨在利用LLM在上下文窗口到达上限时的低效率推理的问题，给 LLM 带来压力，并可能导致其变得无响应。
 
攻击场景示例
 
1. 攻击者反复向LLM模型发送多个请求，这些请求处理起来很困难且成本高昂，从而导致其他用户的服务更差，并增加主机的资源费用。
2. 当 LLM 驱动的工具收集信息以响应良性查询时，会遇到网页上的一段LLM查询文本。这会导致该工具发出更多网页请求，从而导致大量资源消耗。
3. 攻击者不断地用超出其上下文窗口的输入轰炸 LLM。攻击者可能会使用自动化脚本或工具发送大量输入，从而压垮大语言模型的处理能力。因此LLM 消耗过多的计算资源导致变慢或完全无响应。
4. 攻击者向 LLM 发送一系列顺序输入，每个输入都设计为略低于上下文窗口的限制。通过重复提交这些输入，攻击者的目的是耗尽可用的上下文窗口容量。由于 LLM 难以处理其上下文窗口内的每个输入，系统资源变得紧张，可能导致性能下降或完全拒绝服务。
5. 攻击者利用 LLM 递归机制重复触发上下文扩展。通过精心设计利用 LLM 递归行为的输入，攻击者迫使模型重复扩展和处理上下文窗口，从而消耗大量计算资源。这种攻击会给系统带来压力，并可能导致 DoS 情况，导致 LLM 无响应或导致崩溃。
6. 攻击者用大量可变长度输入淹没 LLM，这些输入经过精心设计，以接近或达到上下文窗口的限制。通过用不同长度的输入压垮 LLM，攻击者的目的是利用处理可变长度输入的任何低效率。这种大量的输入给大语言模型资源带来了过多的负载，可能会导致性能下降并阻碍系统响应合法请求的能力。
 
如何预防
 
1. 实施输入验证和清理，以确保用户输入遵守定义的限制并过滤掉任何恶意内容。
2. 限制每个请求或步骤的资源使用，以便涉及复杂部分的请求执行速度更慢。
3. 实施 API 速率限制，以限制单个用户或 IP 地址在特定时间范围内可以发出的请求数量。
4. 限制排队操作（Queued Action)的数量以及系统中响应 LLM 响应的操作总数。
5. 持续监控 LLM 的资源利用率，以识别可能表明 DoS 攻击的异常峰值或模式。
6. 根据LLM上下文窗口设置严格的输入限制，以防止过载和资源耗尽。
7. 提高开发人员对 LLM 中潜在 DoS 威胁的认识，并为安全 LLM 实施提供指南。


参考链接
 
1. LangChain最大迭代次数:  https://twitter.com/hwchase17/status/1608467493877579777
2. 海绵示例: 神经网络的能量延迟攻击:  https ://arxiv.org/abs/2006.03463
3. OWASP DOS 攻击:  https://owasp.org/www-community/attacks/Denial_of_Service
4. 向机器学习: 了解你的上下文窗口:  https://lukebechtel.com/blog/lfm-know-thy-context
